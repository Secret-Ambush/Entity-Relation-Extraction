{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/bristi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/bristi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/bristi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import requests\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import re\n",
    "import xlrd\n",
    "import csv\n",
    "import PyPDF2\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from string import punctuation\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk import tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Entity1': 'Dubai', 'Entity2': 'one', 'Adjectives': [], 'Adverbs': [], 'Numbers': ['one', 'seven', '3', 'million']}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def get_entities(sent):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Document processing\n",
    "    doc = nlp(sent)\n",
    "    ents = list(doc.ents)  # Named entities\n",
    "    noun_chunks = list(doc.noun_chunks)  # Noun phrases\n",
    "\n",
    "    # Initialize variables for entity storage\n",
    "    ent1 = \"\"\n",
    "    ent2 = \"\"\n",
    "    adjectives = []\n",
    "    adverbs = []\n",
    "    numbers = []\n",
    "\n",
    "    # Use named entities and noun chunks to better identify relevant entity pairs\n",
    "    if ents:\n",
    "        ent1 = ents[0].text  # Choose the first named entity as Entity1\n",
    "        if len(ents) > 1:\n",
    "            ent2 = ents[1].text  # Choose the second named entity as Entity2\n",
    "\n",
    "    # If no named entities, use noun chunks\n",
    "    if not ent1 and noun_chunks:\n",
    "        ent1 = noun_chunks[0].text\n",
    "        if len(noun_chunks) > 1:\n",
    "            ent2 = noun_chunks[1].text\n",
    "\n",
    "    # Extract adjectives, adverbs, and numbers\n",
    "    for tok in doc:\n",
    "        if tok.pos_ == \"ADJ\":\n",
    "            adjectives.append(tok.text)\n",
    "        elif tok.pos_ == \"ADV\":\n",
    "            adverbs.append(tok.text)\n",
    "        elif tok.pos_ == 'NUM':\n",
    "            numbers.append(tok.text)\n",
    "\n",
    "    return {\n",
    "        'Entity1': ent1,\n",
    "        'Entity2': ent2,\n",
    "        'Adjectives': adjectives,\n",
    "        'Adverbs': adverbs,\n",
    "        'Numbers': numbers\n",
    "    }\n",
    "\n",
    "# Test the function with a complex sentence\n",
    "sentence = \"Dubai is one of the seven Emirates that constitute the United Arab Emirates (UAE) in the Gulf region with a population of over 3 million people.\"\n",
    "print(get_entities(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Entity1': 'Dubai', 'Entity2': 'Emirates', 'Adjectives': [], 'Adverbs': [], 'Numbers': []}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def get_entities(sent):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Initialize containers\n",
    "    entities = []\n",
    "    adjectives = []\n",
    "    adverbs = []\n",
    "    numbers = []\n",
    "\n",
    "    # Loop over named entities to categorize them\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\", \"LOC\", \"ORG\"]:  # Geographic, Locations, Organizations\n",
    "            entities.append((ent.text, ent.label_))\n",
    "        elif ent.label_ == \"NUM\":  # Numbers\n",
    "            numbers.append(ent.text)\n",
    "\n",
    "    # Loop over each token in the document for adjectives and adverbs\n",
    "    for tok in doc:\n",
    "        if tok.pos_ == \"ADJ\" and tok.dep_.endswith(\"mod\"):\n",
    "            adjectives.append(tok.text)\n",
    "        if tok.pos_ == \"ADV\":\n",
    "            adverbs.append(tok.text)\n",
    "\n",
    "    # Prepare to return the first two identified entities if they exist\n",
    "    ent1 = entities[0][0] if len(entities) > 0 else \"\"\n",
    "    ent2 = entities[1][0] if len(entities) > 1 else \"\"\n",
    "\n",
    "    return {\n",
    "        'Entity1': ent1,\n",
    "        'Entity2': ent2,\n",
    "        'Adjectives': adjectives,\n",
    "        'Adverbs': adverbs,\n",
    "        'Numbers': numbers\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Dubai is one of the seven Emirates that constitute the United Arab Emirates (UAE) in the Gulf region with a population of over 3 million people.\"\n",
    "print(get_entities(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dubai', 'Emirates'), ('Emirates', 'the United Arab Emirates'), ('the United Arab Emirates', 'Gulf')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def get_entity_pairs(sent):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Initialize containers for entities and numbers\n",
    "    places = []\n",
    "    demographics = []\n",
    "\n",
    "    # Extract entities and demographic numbers\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\", \"LOC\", \"ORG\"]:\n",
    "            places.append(ent.text)\n",
    "        elif ent.label_ == \"NUM\" and 'population' in sent[sent.find(ent.text) - 50: sent.find(ent.text) + 50]:\n",
    "            demographics.append(ent.text)\n",
    "\n",
    "    # Initialize pairs\n",
    "    pairs = []\n",
    "    \n",
    "    # Pair places if more than one is identified\n",
    "    if len(places) > 1:\n",
    "        for i in range(len(places) - 1):\n",
    "            pairs.append((places[i], places[i+1]))\n",
    "\n",
    "    # Pair first place with demographic information if available\n",
    "    if places and demographics:\n",
    "        pairs.append((places[0], demographics[0] + \" people\"))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Dubai is one of the seven Emirates that constitute the United Arab Emirates (UAE) in the Gulf region with a population of over 3 million people.\"\n",
    "print(get_entity_pairs(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dubai', 'Emirates'), ('Emirates', 'the United Arab Emirates'), ('the United Arab Emirates', 'Gulf')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def get_entity_pairs(sent):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Initialize containers for entities\n",
    "    places = []\n",
    "    demographics = []\n",
    "\n",
    "    # Extract entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\", \"LOC\", \"ORG\"]:\n",
    "            places.append(ent.text)\n",
    "        elif ent.label_ == \"NUM\" and 'population' in sent[sent.find(ent.text) - 50: sent.find(ent.text) + 50]:\n",
    "            demographics.append(ent.text + \" people\")\n",
    "\n",
    "    # Initialize pairs\n",
    "    pairs = []\n",
    "\n",
    "    # Find and pair specific place with demographics\n",
    "    for place in places:\n",
    "        for demographic in demographics:\n",
    "            if 'population' in sent[sent.find(place):sent.find(demographic)]:\n",
    "                pairs.append((place, demographic))\n",
    "                break  # Break after the first relevant demographic info to avoid duplication\n",
    "\n",
    "    # Pair places sequentially for additional context\n",
    "    if len(places) > 1:\n",
    "        for i in range(len(places) - 1):\n",
    "            pairs.append((places[i], places[i+1]))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Dubai is one of the seven Emirates that constitute the United Arab Emirates (UAE) in the Gulf region with a population of over 3 million people.\"\n",
    "print(get_entity_pairs(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dubai', 'Emirates'), ('Emirates', 'Gulf'), ('Gulf', 'the United Arab Emirates')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def get_entity_pairs(sent):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(sent)\n",
    "\n",
    "    # Initialize containers for entities\n",
    "    places = {}\n",
    "    demographics = []\n",
    "\n",
    "    # Extract entities and demographic numbers\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"GPE\", \"LOC\", \"ORG\"]:\n",
    "            places[ent.text] = ent.start_char  # Store the place and its start position\n",
    "        elif ent.label_ == \"NUM\" and 'population' in sent[sent.find(ent.text) - 50: sent.find(ent.text) + 50]:\n",
    "            demographics.append((ent.text, ent.start_char))\n",
    "\n",
    "    # Initialize pairs\n",
    "    pairs = []\n",
    "    \n",
    "    # Find closest geographic entity for each demographic number\n",
    "    for num, num_pos in demographics:\n",
    "        closest_place = None\n",
    "        min_distance = float('inf')\n",
    "        for place, place_pos in places.items():\n",
    "            distance = abs(place_pos - num_pos)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_place = place\n",
    "        if closest_place:\n",
    "            pairs.append((closest_place, num + \" people\"))\n",
    "\n",
    "    # Additionally, pair places sequentially if more than one is identified\n",
    "    sorted_places = sorted(places.keys())\n",
    "    if len(sorted_places) > 1:\n",
    "        for i in range(len(sorted_places) - 1):\n",
    "            pairs.append((sorted_places[i], sorted_places[i+1]))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Dubai is one of the seven Emirates that constitute the United Arab Emirates (UAE) in the Gulf region with a population of over 3 million people.\"\n",
    "print(get_entity_pairs(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
